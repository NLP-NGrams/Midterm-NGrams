{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Awxczg3xeT2G"
      },
      "source": [
        "# POS tag using Logistic Regression\n",
        "\n",
        "## Loading word embeddings\n",
        "First we load the pretrained GloVe word embeddings trained on twitter data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVknavJleT2S"
      },
      "outputs": [],
      "source": [
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "import numpy as np\n",
        "import os.path\n",
        "\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, classification_report\n",
        "from tqdm import tqdm\n",
        "\n",
        "TRAIN_DATA_PATH = 'data/train.txt'\n",
        "\n",
        "# create a sklearn model\n",
        "vectorizer = DictVectorizer(sparse=False)\n",
        "\n",
        "# Create a directory 'pretrained_embeds/' in the same directory as this notebook\n",
        "# Download twitter embeddings from http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
        "# Unzip it and place file 'glove.twitter.27B.25d.txt' in 'pretrained_embeds/' directory.\n",
        "\n",
        "# We are doing it with 25 dimensional word embeddings, however we can try doing with more \n",
        "# dimensional embeddings available.\n",
        "\n",
        "# If glove embeds is not in word2vec form then first convert it then load it\n",
        "if os.path.isfile('pretrained_embeds/gensim_glove_vectors.txt'):\n",
        "    glove_model = KeyedVectors.load_word2vec_format(\"pretrained_embeds/gensim_glove_vectors.txt\", binary=False)\n",
        "else:\n",
        "    glove2word2vec(glove_input_file=\"pretrained_embeds/glove.twitter.27B.50d.txt\", word2vec_output_file=\"pretrained_embeds/gensim_glove_vectors.txt\")\n",
        "    glove_model = KeyedVectors.load_word2vec_format(\"pretrained_embeds/gensim_glove_vectors.txt\", binary=False)\n",
        "\n",
        "def get_embed(word):\n",
        "    # Case folding\n",
        "    word = word.lower()\n",
        "    try:\n",
        "        return (glove_model.get_vector(word))\n",
        "    except:\n",
        "        return (glove_model.get_vector('unk'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4t71o7keT2a"
      },
      "source": [
        "## Creating dataset\n",
        "\n",
        "Loading data using nltk (we are using brown corpus) and splitting data in train and test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "FhDtmNVjeT2d"
      },
      "outputs": [],
      "source": [
        "# tagged_sents = brown.tagged_sents(tagset='universal')\n",
        "with open('./traino.txt', 'r') as infile:\n",
        "    data = infile.read()\n",
        "    # Extracting the sentences from data and creating a sentences list []\n",
        "    sentences = data.strip().split('\\n\\n')\n",
        "    processed_sentences = []\n",
        "    for sentence in sentences:\n",
        "        sent = []\n",
        "        # Split the sentence into individual lines (tokens and tags)\n",
        "        lines = sentence.strip().split('\\n')\n",
        "        # Extract the tokens and tags from each line\n",
        "        tokens_tags = [line.split() for line in lines]\n",
        "        # Extract the tokens and tags into separate lists\n",
        "        for token_tag in tokens_tags:\n",
        "            token, tag = token_tag[0], token_tag[1]\n",
        "            sent.append((token, tag))\n",
        "        processed_sentences.append(sent)\n",
        "\n",
        "\n",
        "# Splitting train and test(80:20)\n",
        "tagged_sents = processed_sentences\n",
        "train_len = int(len(tagged_sents) * 0.8)\n",
        "train_sents = tagged_sents\n",
        "test_sents = tagged_sents[train_len:]\n",
        "\n",
        "brown_tags_words = []\n",
        "brown_tags_words_test = []\n",
        "\n",
        "train_tags = []\n",
        "train_words = []\n",
        "train_embeds = []\n",
        "\n",
        "test_tags = []\n",
        "test_words = []\n",
        "test_embeds = []\n",
        "# Create Train data\n",
        "for sent in train_sents:\n",
        "    brown_tags_words.extend([ (tag, word) for (word, tag) in sent ])\n",
        "\n",
        "# # Seperate out tag and word sequences\n",
        "for (tag, word) in brown_tags_words:\n",
        "    train_tags.append(tag)\n",
        "    train_words.append(word)\n",
        "    # golve train_embeds\n",
        "    train_embeds.append(get_embed(word))\n",
        "\n",
        "# Create Test data\n",
        "for sent in test_sents:\n",
        "    brown_tags_words_test.extend([ (tag, word) for (word, tag) in sent ])\n",
        "\n",
        "# Seperate out tag and word sequences\n",
        "for (tag, word) in brown_tags_words_test:\n",
        "    test_tags.append(tag)\n",
        "    test_words.append(word)\n",
        "    # golve test_embeds\n",
        "    test_embeds.append(get_embed(word))\n",
        "\n",
        "# # # Adding bias at the end of each embedding\n",
        "train_embeds = np.asarray(train_embeds)\n",
        "test_embeds = np.asarray(test_embeds)\n",
        "\n",
        "# # Adding bias at the end of each embedding\n",
        "temp = np.ones((train_embeds.shape[0], train_embeds.shape[1] + 1))\n",
        "temp[:,:-1] = train_embeds\n",
        "train_embeds = temp\n",
        "\n",
        "# # Adding bias at the end of each embedding\n",
        "temp = np.ones((test_embeds.shape[0], test_embeds.shape[1] + 1))\n",
        "temp[:,:-1] = test_embeds\n",
        "test_embeds = temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgBEAyVheT2h",
        "outputId": "cb04f310-4294-4c1e-a622-ca46b6e45142"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_iter reached after 677 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "lr = LogisticRegression(solver='newton-cg', verbose=1, n_jobs=-1)\n",
        "lr.fit(train_embeds, train_tags)\n",
        "filename = 'glovelr.pkl'\n",
        "import joblib\n",
        "joblib.dump(lr, filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPkzw4kIeT2j",
        "outputId": "d76179f2-827f-4acd-9d55-7c18457666a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.843319381084513\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           #       1.00      1.00      1.00         9\n",
            "           $       1.00      1.00      1.00       364\n",
            "          ''       1.00      0.97      0.98       263\n",
            "           (       0.00      0.00      0.00        62\n",
            "           )       0.00      0.00      0.00        63\n",
            "           ,       1.00      1.00      1.00      2166\n",
            "           .       1.00      1.00      1.00      1773\n",
            "           :       1.00      0.96      0.98       239\n",
            "          CC       1.00      1.00      1.00      1067\n",
            "          CD       0.65      1.00      0.79      1864\n",
            "          DT       1.00      0.98      0.99      3510\n",
            "          EX       0.90      1.00      0.95        43\n",
            "          FW       0.00      0.00      0.00         3\n",
            "          IN       0.93      0.98      0.95      4548\n",
            "          JJ       0.73      0.62      0.67      2488\n",
            "         JJR       0.79      0.85      0.82       172\n",
            "         JJS       0.91      0.83      0.87        82\n",
            "          MD       0.99      1.00      1.00       432\n",
            "          NN       0.74      0.80      0.77      5945\n",
            "         NNP       0.78      0.67      0.72      4338\n",
            "        NNPS       0.80      0.04      0.08        99\n",
            "         NNS       0.85      0.86      0.86      2766\n",
            "         PDT       0.00      0.00      0.00        11\n",
            "         POS       0.84      1.00      0.91       370\n",
            "         PRP       0.99      1.00      0.99       691\n",
            "        PRP$       0.99      1.00      1.00       374\n",
            "          RB       0.74      0.74      0.74      1312\n",
            "         RBR       0.84      0.29      0.43        55\n",
            "         RBS       0.87      0.98      0.92        48\n",
            "          RP       0.00      0.00      0.00        26\n",
            "          TO       1.00      1.00      1.00      1058\n",
            "          VB       0.74      0.64      0.69      1177\n",
            "         VBD       0.75      0.77      0.76      1444\n",
            "         VBG       0.74      0.67      0.70       638\n",
            "         VBN       0.60      0.52      0.56       968\n",
            "         VBP       0.73      0.65      0.69       541\n",
            "         VBZ       0.92      0.81      0.86       856\n",
            "         WDT       0.99      0.53      0.69       196\n",
            "          WP       1.00      1.00      1.00       102\n",
            "         WP$       1.00      1.00      1.00         8\n",
            "         WRB       1.00      1.00      1.00        86\n",
            "          ``       1.00      1.00      1.00       269\n",
            "\n",
            "    accuracy                           0.84     42526\n",
            "   macro avg       0.78      0.74      0.75     42526\n",
            "weighted avg       0.84      0.84      0.84     42526\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "lrn = joblib.load('glovelr.model')\n",
        "predictions = lr.predict(test_embeds)\n",
        "print('Accuracy:', accuracy_score(test_tags, predictions))\n",
        "print(classification_report(test_tags, predictions))\n",
        "# custom word2vec model trained on our training data\n",
        "# Accuracy: Accuracy: 0.7612754550157551\n",
        "# pretrained glove gensim model\n",
        "# Accuracy: 0.843319381084513\n",
        "# pretrained word2vec gensim model\n",
        "# Accuracy: 0.7014532286130838"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "c06USG8heT2k"
      },
      "outputs": [],
      "source": [
        "with open('./test_data.txt', 'r',encoding=\"utf8\") as file:\n",
        "    data = file.read()\n",
        "    sentences = data.strip().split('\\n\\n')\n",
        "    processed_sentences = []\n",
        "    for sentence in sentences:\n",
        "        sent = []\n",
        "        # Split the sentence into individual lines (tokens and tags)\n",
        "        lines = sentence.strip().split('\\n')\n",
        "        # append the lines to the processed_sentences list\n",
        "        processed_sentences.append(lines)\n",
        "\n",
        "test_embeds1 = []\n",
        "test_words1 = []\n",
        "for sent in processed_sentences:\n",
        "    # test_tags.append(tag)\n",
        "    for word in sent:\n",
        "        test_words1.append(word)\n",
        "    # golve test_embeds\n",
        "        test_embeds1.append(get_embed(word))\n",
        "\n",
        "# # Adding bias at the end of each embedding\n",
        "test_embeds1 = np.asarray(test_embeds1)\n",
        "temp = np.ones((test_embeds1.shape[0], test_embeds1.shape[1] + 1))\n",
        "temp[:,:-1] = test_embeds1\n",
        "test_embeds1 = temp\n",
        "\n",
        "predictions = lr.predict(test_embeds1)\n",
        "# print(len(predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNyLAU4ceT2l",
        "outputId": "4b9b0207-8443-4fc3-ed2d-9526399aa907"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing to file...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "print(\"Writing to file...\")\n",
        "with open(\"FILENAME.txt\", \"w\") as output:\n",
        "    for i in range(len(predictions)):\n",
        "        if test_words1[i] == '.':\n",
        "            output.write(test_words1[i] + ' ' + predictions[i] + '\\n')\n",
        "            output.write('\\n')\n",
        "        else:\n",
        "          output.write(test_words1[i] + ' ' + predictions[i] + '\\n')\n",
        "      # output.write('\\n')\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yH11fu-WeT2o"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "822aee1c7545337081ed149134b7b9af4387d983b56a0aa2206d27561e7a0868"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
